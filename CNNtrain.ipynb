{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "root_dir = \"training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = len(files)\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "print(files[0])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patches from input images\n",
    "patch_size = 16 # each patch is 16*16 pixels\n",
    "\n",
    "img_patches = [img_crop(imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "gt_patches = [img_crop(gt_imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "\n",
    "# Linearize list of patches\n",
    "img_patches = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
    "gt_patches =  np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "\n",
    "print(img_patches.shape)\n",
    "print(gt_patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, ReLU, Dropout, Flatten, Dense, ELU\n",
    "from keras.regularizers import l2\n",
    "\n",
    "INPUT_SHAPE=(16, 16, 3)\n",
    "REG = 1e-6\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 64,\n",
    "                 kernel_size = (5, 5),\n",
    "                 strides = (1, 1),\n",
    "                 padding='same',\n",
    "                 input_shape=INPUT_SHAPE))\n",
    "model.add(ELU())\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "#                       strides=None,\n",
    "#                       padding='same'))\n",
    "model.add(Conv2D(filters = 64,\n",
    "                 kernel_size = (5, 5),\n",
    "                 strides = (2, 2),\n",
    "                 padding='same',\n",
    "                 input_shape=INPUT_SHAPE))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters = 128,\n",
    "                 kernel_size = (4, 4),\n",
    "                 strides = (1, 1),\n",
    "                 padding='same',\n",
    "                 input_shape=INPUT_SHAPE))\n",
    "model.add(ELU())\n",
    "#model.add(ReLU(max_value=2))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "#                       strides=None,\n",
    "#                       padding='same'))\n",
    "model.add(Conv2D(filters = 128,\n",
    "                 kernel_size = (4, 4),\n",
    "                 strides = (2, 2),\n",
    "                 padding='same',\n",
    "                 input_shape=INPUT_SHAPE))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters = 256,\n",
    "                 kernel_size = (3, 3),\n",
    "                 strides = (1, 1),\n",
    "                 padding='same',\n",
    "                 input_shape=INPUT_SHAPE))\n",
    "model.add(ELU())\n",
    "#model.add(ReLU(max_value=2))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "#                       strides=None,\n",
    "#                       padding='same'))\n",
    "model.add(Conv2D(filters = 256,\n",
    "                 kernel_size = (3, 3),\n",
    "                 strides = (2, 2),\n",
    "                 padding='same',\n",
    "                 input_shape=INPUT_SHAPE))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, kernel_regularizer=l2(REG)))\n",
    "model.add(ELU())\n",
    "#model.add(ReLU(max_value=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64, kernel_regularizer=l2(REG)))\n",
    "model.add(ELU())\n",
    "#model.add(ReLU(max_value=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, kernel_regularizer=l2(REG)))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "opt = Adam(lr=0.001) # Adam optimizer with default initial learning rate\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "def value_to_class(v):\n",
    "    df = np.sum(v)\n",
    "    if df > foreground_threshold:\n",
    "        return [1, 0]\n",
    "    else:\n",
    "        return [0, 1]\n",
    "\n",
    "X = np.asarray([ img_patches[i] for i in range(len(img_patches))])\n",
    "Y = np.asarray([value_to_class(np.mean(gt_patches[i])) for i in range(len(gt_patches))])\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "STEPS_PER_EPOCH = 125\n",
    "BATCH_SIZE = 125\n",
    "EPOCHS = 200\n",
    "\n",
    "datagen = ImageDataGenerator(zca_whitening=True,\n",
    "                             rotation_range=90,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True)\n",
    "\n",
    "datagen.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(datagen.flow(X, Y, batch_size=BATCH_SIZE),\n",
    "          steps_per_epoch=X.shape[0] // BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
